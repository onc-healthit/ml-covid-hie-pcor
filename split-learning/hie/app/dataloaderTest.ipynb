{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from icdmappings import Mapper\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset, dataloader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from functools import reduce\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "pd.set_option(\"mode.chained_assignment\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient IDX                                                                                               1\n",
      "PatientAdministrationGenderCode                                                                        male\n",
      "PatientBirthDateTime                                                                                     62\n",
      "Systolic Blood Pressure                                                                                    \n",
      "Diastolic Blood Pressure                                                                                   \n",
      "Body Weight                                                                                                \n",
      "Body Height                                                                                                \n",
      "BMI                                                                                                        \n",
      "Body Temperature                                                                                           \n",
      "Heart Rate                                                                                                 \n",
      "Oxygen Saturation                                                                                          \n",
      "Respiratory Rate                                                                                           \n",
      "Acute COVID 19 Diagnosis                                                                                  0\n",
      "Post Acute Sequelae of Sars Cov 2 infection (PASC)                                                        0\n",
      "Acute Myocardial Infarction                                                                               0\n",
      "Ischemic Heart Disease                                                                                    0\n",
      "Acute Coronary Syndromes                                                                                  0\n",
      "Bronchiectasis Diagnosis                                                                                  0\n",
      "Hypertension Pulmonary hypertension                                                                        \n",
      "Pulmonary embolism diagnosis                                                                              0\n",
      "Cerebrovascular disease diagnosis                                                                         0\n",
      "Chronic kidney disease all stages (1 through 5)                                                           0\n",
      "Cirrhosis or other liver disease                                                                          0\n",
      "Chronic obstructive pulmonary disease (COPD) Diagnosis                                                    0\n",
      "Type 1 Diabetes                                                                                           0\n",
      "Type II Diabetes                                                                                          0\n",
      "Heart Failure Diagnosis                                                                                   0\n",
      "Coronary Artery Disease No MI                                                                             0\n",
      "Cardiomyopathy                                                                                            0\n",
      "Interstitial lung disease diagnosis                                                                       0\n",
      "Ever tobacco smoker                                                                                       0\n",
      "Tuberculosis Disorders                                                                                    0\n",
      "Obesity Conditions                                                                                        0\n",
      "Pregnancy                                                                                                 0\n",
      "Depression Diagnosis                                                                                      0\n",
      "Schizophrenia                                                                                             0\n",
      "HIV                                                                                                       0\n",
      "Dementia and Related Intracranial Pathologies                                                             0\n",
      "Overweight or Obese                                                                                       0\n",
      "Sickle cell disease and related blood disorders                                                           0\n",
      "Substance abuse                                                                                           0\n",
      "Cystic fibrosis                                                                                           0\n",
      "Thalassemia                                                                                               0\n",
      "Asthma diagnosis                                                                                          0\n",
      "Hypertension  Primary and Secondary Diagnosis                                                             0\n",
      "Chronic Pain Conditions                                                                                   0\n",
      "PostTraumatic stress disorder PTSD                                                                        0\n",
      "Myalgic Encephalomyelitis or Chronic Fatigue Syndrome                                                     0\n",
      "Postural tachycardia syndrome (POTS) Diagnosis                                                            0\n",
      "Ehlers-Danlos syndrome                                                                                    0\n",
      "Stroke                                                                                                    0\n",
      "Food insecurity diagnoses                                                                                 0\n",
      "Housing insecurity                                                                                        0\n",
      "Transportation insecurity                                                                                 0\n",
      "SNOMED Codes 0                                                                                    224295006\n",
      "SNOMED Codes 1                                                                                             \n",
      "SNOMED Codes 2                                                                                             \n",
      "SNOMED Codes 3                                                                                             \n",
      "SNOMED Codes Other                                                                                         \n",
      "ICD-10 Codes 0                                                                                             \n",
      "ICD-10 Codes 1                                                                                             \n",
      "ICD-10 Codes 2                                                                                             \n",
      "ICD-10 Codes 3                                                                                             \n",
      "ICD-10 Codes Other                                                                                         \n",
      "COVID19 Lab Tests                                                                                          \n",
      "Hemoglobin A1C                                                                                             \n",
      "Blood Urea Nitrogen                                                                                        \n",
      "Bilirubin lab test                                                                                         \n",
      "Troponin Lab Test                                                                                          \n",
      "Ferritin                                                                                                   \n",
      "Glucose Tolerance Testing                                                                                  \n",
      "Cerebral Spinal Fluid (CSF) Analysis                                                                       \n",
      "Arterial Blood Gas                                                                                         \n",
      "Comprehensive Metabolic Panel                                                                              \n",
      "Chloride  Urine                                                                                            \n",
      "Calcium in Blood  Serum or Plasma                                                                          \n",
      "Magnesium in Blood  Serum or Plasma                                                                        \n",
      "Magnesium in Urine                                                                                         \n",
      "Chloride  Blood  Serum  or Plasma                                                                          \n",
      "Creatinine  Urine                                                                                          \n",
      "Creatinine  Blood  Serum  or Plasma                                                                        \n",
      "Phosphate Blood  Serum  or Plasma                                                                          \n",
      "Coagulation Assay                                                                                          \n",
      "Complete Blood Count                                                                                       \n",
      "Creatine Kinase Blood  Serum  or Plasma                                                                    \n",
      "D Dimer Test                                                                                               \n",
      "Electrolytes Panel Blood  Serum  or Plasma                                                                 \n",
      "Inflammatory Markers (CRP) Blood  Serum  or Plasma                                                         \n",
      "Lipid Serum  or Plasma                                                                                     \n",
      "Sputum Culture                                                                                             \n",
      "Urine Collection 24 Hours                                                                                  \n",
      "Urine Routine                                                                                              \n",
      "Smoking Status                                                                                             \n",
      "Procedure Codes 0                                                                                          \n",
      "Procedure Codes 1                                                                                          \n",
      "Procedure Codes 2                                                                                          \n",
      "Procedure Codes 3                                                                                          \n",
      "Procedure Codes Other                                                                                      \n",
      "Projected_Note_Embeddings                                 [0.05697727729905562, 0.6598718627497779, -0.3...\n",
      "Projected_Med_Embeddings                                  [0.19206795927612624, 0.8154250324890344, 0.27...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pklData = pd.read_pickle(\"./data/patientData_1.pkl\")\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(pklData.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HIEDATA2(Dataset[Any]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataLocation=\"/code/app/data/\",\n",
    "        cacheRowLimit=200,\n",
    "        cacheDir=\"./cache\",\n",
    "        debug=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.debug = debug\n",
    "        self.dataPath = Path(dataLocation)\n",
    "        self.cacheDir = Path(cacheDir)\n",
    "        os.makedirs(self.cacheDir, exist_ok=True)\n",
    "        self.cacheIndex = 0\n",
    "        if not self.dataPath.is_dir():\n",
    "            raise FileNotFoundError(\"Data directory doesn't exist\")\n",
    "        if debug:\n",
    "            print(\"Found data directory\")\n",
    "        self.cacheRowLimit = cacheRowLimit\n",
    "        self.dataFiles = list(self.dataPath.glob(\"*.pkl\"))\n",
    "        if not len(self.dataFiles):\n",
    "            raise FileNotFoundError(\"No PKLs found in data directory\")\n",
    "        if debug:\n",
    "            print(f\"Found {len(self.dataFiles)} PKL files\")\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        if debug:\n",
    "            print(f\"Using {self.device}\")\n",
    "        self.labelEncoder = LabelEncoder()\n",
    "        self.currentFileIdx = None\n",
    "\n",
    "        self.IDColumn = \"Patient IDX\"\n",
    "        self.categoricalColumns = {\n",
    "            \"PatientAdministrationGenderCode\": None,\n",
    "            \"Smoking Status\": None,\n",
    "            # \"Urine Routine\",\n",
    "        }\n",
    "        self.categEmbedColumns = {\n",
    "            \"SnomedEmbed\": [\n",
    "                \"SNOMED Codes 0\",\n",
    "                \"SNOMED Codes 1\",\n",
    "                \"SNOMED Codes 2\",\n",
    "                \"SNOMED Codes 3\",\n",
    "                \"SNOMED Codes Other\",\n",
    "            ],\n",
    "            \"ProcedureEmbed\": [\n",
    "                \"Procedure Codes 0\",\n",
    "                \"Procedure Codes 1\",\n",
    "                \"Procedure Codes 2\",\n",
    "                \"Procedure Codes 3\",\n",
    "                \"Procedure Codes Other\",\n",
    "            ],\n",
    "        }\n",
    "        self.ignoreColumns = [\n",
    "            \"ICD-10 Codes 0\",\n",
    "            \"ICD-10 Codes 1\",\n",
    "            \"ICD-10 Codes Other\",\n",
    "            \"ICD-10 Codes 2\",\n",
    "            \"ICD-10 Codes 3\",\n",
    "        ]\n",
    "        self.cliNotesColumns = [\n",
    "            \"Projected_Med_Embeddings\",\n",
    "            \"Projected_Note_Embeddings\",\n",
    "        ]\n",
    "        self.yVar = [\n",
    "            \"Chronic kidney disease all stages (1 through 5)\",\n",
    "            \"Acute Myocardial Infarction\",\n",
    "            \"Hypertension Pulmonary hypertension\",\n",
    "            \"Ischemic Heart Disease\",\n",
    "        ]\n",
    "        self.yVarList = {\n",
    "            \"Diabetes\": [\n",
    "                \"Type 1 Diabetes\",\n",
    "                \"Type II Diabetes\",\n",
    "            ]\n",
    "        }\n",
    "        self.continuousColumns = [\n",
    "            \"PatientBirthDateTime\",\n",
    "            \"Systolic Blood Pressure\",\n",
    "            \"Diastolic Blood Pressure\",\n",
    "            \"Body Weight\",\n",
    "            \"Body Height\",\n",
    "            \"BMI\",\n",
    "            \"Body Temperature\",\n",
    "            \"Heart Rate\",\n",
    "            \"Oxygen Saturation\",\n",
    "            \"Respiratory Rate\",\n",
    "            \"Hemoglobin A1C\",\n",
    "            \"Blood Urea Nitrogen\",\n",
    "            \"Bilirubin lab test\",\n",
    "            \"Troponin Lab Test\",\n",
    "            \"Ferritin\",\n",
    "            \"Glucose Tolerance Testing\",\n",
    "            \"Cerebral Spinal Fluid (CSF) Analysis\",\n",
    "            \"Arterial Blood Gas\",\n",
    "            \"Comprehensive Metabolic Panel\",\n",
    "            \"Chloride  Urine\",\n",
    "            \"Calcium in Blood  Serum or Plasma\",\n",
    "            \"Magnesium in Blood  Serum or Plasma\",\n",
    "            \"Magnesium in Urine\",\n",
    "            \"Chloride  Blood  Serum  or Plasma\",\n",
    "            \"Creatinine  Urine\",\n",
    "            \"Creatinine  Blood  Serum  or Plasma\",\n",
    "            \"Phosphate Blood  Serum  or Plasma\",\n",
    "            \"Coagulation Assay\",\n",
    "            \"Complete Blood Count\",\n",
    "            \"Creatine Kinase Blood  Serum  or Plasma\",\n",
    "            \"D Dimer Test\",\n",
    "            \"Electrolytes Panel Blood  Serum  or Plasma\",\n",
    "            \"Inflammatory Markers (CRP) Blood  Serum  or Plasma\",\n",
    "            \"Lipid Serum  or Plasma\",\n",
    "            \"Sputum Culture\",\n",
    "            \"Urine Collection 24 Hours\",\n",
    "            # \"Urine Routine\", This is string, should be included in categorical\n",
    "        ]\n",
    "        self.contData = []\n",
    "        self.categData = []\n",
    "        self.clinData = []\n",
    "        self.labels = []\n",
    "        self.dataLen = 0\n",
    "        maxRows = 0\n",
    "        self.labelEncoder = LabelEncoder()\n",
    "        self.clinicalbert_model_name = (\n",
    "            \"emilyalsentzer/Bio_ClinicalBERT\"  # \"medicalai/ClinicalBERT\"\n",
    "        )\n",
    "        self.clinicalbert_model = AutoModel.from_pretrained(\n",
    "            self.clinicalbert_model_name\n",
    "        ).to(self.device)\n",
    "        self.clinicalbert_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.clinicalbert_model_name\n",
    "        )\n",
    "        if debug:\n",
    "            print(\"Pre Processing Data and creating Cache...\")\n",
    "        initCategData = []\n",
    "        for f in tqdm(self.dataFiles):\n",
    "            df = pd.read_pickle(f)\n",
    "            initCategData.append(\n",
    "                df[list(self.categoricalColumns.keys())].astype(\"string\")\n",
    "            )\n",
    "        initCategData = pd.concat(initCategData, ignore_index=True)\n",
    "        for categLabel in self.categoricalColumns:\n",
    "            self.categoricalColumns[categLabel] = LabelEncoder().fit(\n",
    "                initCategData[categLabel]\n",
    "            )\n",
    "        for f in tqdm(self.dataFiles):\n",
    "            df = pd.read_pickle(f)\n",
    "            patientIDXs = df[self.IDColumn].unique()\n",
    "            for patientID in tqdm(patientIDXs[:5]):\n",
    "                contStack = []\n",
    "                categStack = []\n",
    "                clinStack = []\n",
    "                # print(patientID)\n",
    "                patientRows = df.loc[df[self.IDColumn] == patientID]\n",
    "                patientRows = patientRows.ffill().bfill().fillna(0)\n",
    "                contData = patientRows[self.continuousColumns]\n",
    "                contData = contData.reset_index().drop(columns=\"index\")\n",
    "                clinicalEmbeddings = patientRows[self.cliNotesColumns]\n",
    "                # categData = self.labelEncoder.fit_transform(\n",
    "                # patientRows[self.categoricalColumns].fillna(0)\n",
    "                # )\n",
    "                for categEmbed in self.categEmbedColumns:\n",
    "                    subset = (\n",
    "                        patientRows[self.categEmbedColumns[categEmbed]]\n",
    "                        .reset_index()\n",
    "                        .drop(columns=\"index\")\n",
    "                    )\n",
    "                    newData = []\n",
    "                    subset = subset.astype(\"string\")\n",
    "                    # print(patientID, categEmbed)\n",
    "                    for i in range(len(subset)):\n",
    "                        # print(i)\n",
    "                        newData.append(\n",
    "                            self.genEmbeddings(\"\".join(subset.loc[i].to_list()))\n",
    "                        )\n",
    "                    clinicalEmbeddings[categEmbed] = newData\n",
    "                    # print(clinicalEmbeddings)\n",
    "                    # print(\"-------------------\")\n",
    "                    del newData\n",
    "                # for i in clinicalEmbeddings.columns:\n",
    "                #     print(len(clinicalEmbeddings[i].to_numpy()[0]))\n",
    "                clinicalEmbeddings = clinicalEmbeddings.to_numpy()\n",
    "                categData = patientRows[self.categoricalColumns.keys()].to_numpy()\n",
    "                for i, d in enumerate(self.categoricalColumns):\n",
    "                    categData[:, i] = self.categoricalColumns[d].transform(\n",
    "                        categData[:, i]\n",
    "                    )\n",
    "                # for d in range(len(contData[\"PatientBirthDateTime\"])):\n",
    "                #     contData.at[d, \"PatientBirthDateTime\"] = self.dateToInt(\n",
    "                #         contData[\"PatientBirthDateTime\"][d]\n",
    "                #     )\n",
    "                for col in contData:\n",
    "                    contData[col] = pd.to_numeric(contData[col])\n",
    "                # with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "                #     print(contData)\n",
    "                # Z Score Norming continuous values.\n",
    "                contData = (\n",
    "                    ((contData - contData.mean()) / (contData.std() + 1e-100))\n",
    "                    .fillna(0)\n",
    "                    .to_numpy()\n",
    "                )\n",
    "                assert (\n",
    "                    len(contData) == len(categData) == len(clinicalEmbeddings)\n",
    "                ), print(\n",
    "                    f\"{len(contData)}, {len(categData)}, {len(clinicalEmbeddings)}, {patientID}\"\n",
    "                )\n",
    "                labels = patientRows[self.yVar]\n",
    "                for col in self.yVarList:\n",
    "                    orValues = reduce(\n",
    "                        lambda a, b: a | b, patientRows[self.yVarList[col]].T.to_numpy()\n",
    "                    )\n",
    "                    labels.loc[:, col] = orValues\n",
    "                labels = (\n",
    "                    labels.reset_index()\n",
    "                    .drop(columns=\"index\")\n",
    "                    .replace(\"\", np.nan)\n",
    "                    .fillna(0)\n",
    "                    .astype(int)\n",
    "                    .to_numpy()\n",
    "                )\n",
    "                for dRow in range(len(labels)):\n",
    "                    contStack.append(contData[dRow])\n",
    "                    categStack.append(categData[dRow])\n",
    "                    clinStack.append(np.stack(clinicalEmbeddings[dRow]))\n",
    "                    if np.any(labels[dRow]):\n",
    "                        # print(dRow)\n",
    "                        self.contData.append(np.stack(deepcopy(contStack)))\n",
    "                        self.categData.append(np.stack(deepcopy(categStack)))\n",
    "                        self.clinData.append(np.stack(deepcopy(clinStack)))\n",
    "                        self.labels.append(np.stack(deepcopy(labels[dRow])))\n",
    "                        self.dataLen += 1\n",
    "                        # if len(self.contData) > self.cacheRowLimit:\n",
    "                        #     self.cacheToDisk()\n",
    "                    else:\n",
    "                        pass\n",
    "                if self.contData:\n",
    "                    if maxRows < len(self.contData[-1]):\n",
    "                        maxRows = len(self.contData[-1])\n",
    "                del contStack, categStack, clinStack\n",
    "\n",
    "                # break\n",
    "                # break\n",
    "\n",
    "        print(f\"Max roll up Rows: {maxRows}\")\n",
    "        for i, d in enumerate(self.contData):\n",
    "            self.contData[i] = np.vstack(\n",
    "                [\n",
    "                    d,\n",
    "                    np.zeros(\n",
    "                        (maxRows - d.shape[0], *d.shape[1:]),\n",
    "                        dtype=d.dtype,\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        for i, d in enumerate(self.categData):\n",
    "            self.categData[i] = np.vstack(\n",
    "                [\n",
    "                    d,\n",
    "                    np.zeros(\n",
    "                        (maxRows - d.shape[0], *d.shape[1:]),\n",
    "                        dtype=d.dtype,\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        for i, d in enumerate(self.clinData):\n",
    "            self.clinData[i] = np.vstack(\n",
    "                [\n",
    "                    d,\n",
    "                    np.zeros(\n",
    "                        (maxRows - d.shape[0], *d.shape[1:]),\n",
    "                        dtype=d.dtype,\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        # print(np.stack(self.contData).shape)\n",
    "        self.contData = torch.tensor(self.contData)\n",
    "        self.contData = self.contData.reshape((len(self.contData), -1))\n",
    "        self.categData = torch.tensor(np.array(self.categData).astype(int))\n",
    "        self.categData = self.categData.reshape((len(self.categData), -1))\n",
    "        self.clinData = torch.tensor(self.clinData)\n",
    "        self.clinData = self.clinData.reshape((len(self.clinData), -1))\n",
    "        # print(self.labels)\n",
    "        self.contDataInputShape = self.contData.shape[-1]\n",
    "        self.categDataInputShape = self.categData.shape[-1]\n",
    "        self.clinDataInputShape = self.clinData.shape[-1]\n",
    "        self.labels = torch.tensor(np.array(self.labels).astype(int))\n",
    "        self.labelOutputShape = self.labels.shape[-1]\n",
    "        while len(self.contData) != 0:\n",
    "            self.cacheToDisk()\n",
    "        if debug:\n",
    "            print(\"Created Cache\")\n",
    "        self.loadRequiredFile(0)\n",
    "        if debug:\n",
    "            print(\"Done initializing Dataset\")\n",
    "\n",
    "    def getTotalRowCount(self):\n",
    "        totalRows = 0\n",
    "        for dataFile in self.dataFiles:\n",
    "            totalRows += len(pd.read_pickle(dataFile))\n",
    "        return totalRows\n",
    "\n",
    "    def getShapes(self):\n",
    "        return (\n",
    "            self.contDataInputShape,\n",
    "            self.categDataInputShape,\n",
    "            self.clinDataInputShape,\n",
    "            self.labelOutputShape\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fileIDX = index // self.cacheRowLimit\n",
    "        localIDX = index % self.cacheRowLimit\n",
    "        if self.currentFileIdx != fileIDX:\n",
    "            self.loadRequiredFile(fileIDX)\n",
    "        return (\n",
    "            self.contData[localIDX],\n",
    "            self.categData[localIDX],\n",
    "            self.clinData[localIDX],\n",
    "            self.labels[localIDX],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataLen\n",
    "\n",
    "    def loadRequiredFile(self, fileIDX):\n",
    "        if self.currentFileIdx == fileIDX:\n",
    "            return\n",
    "        else:\n",
    "            if self.debug:\n",
    "                print(f\"Loading Cache File {fileIDX+1}\")\n",
    "            data = torch.load(self.cacheDir / f\"dataCache{fileIDX}.pkl\")\n",
    "            self.contData = data[\"cont\"]\n",
    "            self.categData = data[\"categ\"]\n",
    "            self.clinData = data[\"cli\"]\n",
    "            self.labels = data[\"labels\"]\n",
    "            self.currentFileIdx = fileIDX\n",
    "\n",
    "    def cacheToDisk(self):\n",
    "        torch.save(\n",
    "            {\n",
    "                \"cont\": self.contData[: self.cacheRowLimit],\n",
    "                \"categ\": self.categData[: self.cacheRowLimit],\n",
    "                \"cli\": self.clinData[: self.cacheRowLimit],\n",
    "                \"labels\": self.labels[: self.cacheRowLimit],\n",
    "            },\n",
    "            self.cacheDir / f\"dataCache{self.cacheIndex}.pkl\",\n",
    "        )\n",
    "        self.contData = self.contData[self.cacheRowLimit :]\n",
    "        self.categData = self.categData[self.cacheRowLimit :]\n",
    "        self.clinData = self.clinData[self.cacheRowLimit :]\n",
    "        self.labels = self.labels[self.cacheRowLimit :]\n",
    "        gc.collect()\n",
    "        if self.debug:\n",
    "            print(f\"Creating Cache File {self.cacheIndex + 1}\")\n",
    "        self.cacheIndex += 1\n",
    "\n",
    "    def chunkText(self, text, chunkSize=512):\n",
    "        chunks = []\n",
    "        idx = 0\n",
    "        while idx < len(text):\n",
    "            end = min(idx + chunkSize, len(text))\n",
    "            chunk = text[idx:end]\n",
    "            if end < len(text) and not re.match(r\"\\b\\w+\\b$\", chunk):\n",
    "                chunk += \" \" + text[end]\n",
    "                end += 1\n",
    "            chunks.append(chunk)\n",
    "            idx = end\n",
    "        return chunks\n",
    "\n",
    "    def genEmbeddings(self, text):\n",
    "        chunks = self.chunkText(text)\n",
    "        embeddings = []\n",
    "        for chunk in chunks:\n",
    "            encoded_input = self.clinicalbert_tokenizer(\n",
    "                chunk, return_tensors=\"pt\", padding=\"max_length\", truncation=True\n",
    "            )\n",
    "            encoded_input = encoded_input.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                output = self.clinicalbert_model(**encoded_input)\n",
    "                last_hidden_state = output.last_hidden_state\n",
    "                chunk_embedding = torch.mean(last_hidden_state, dim=1)\n",
    "                embeddings.append(chunk_embedding.cpu().detach().numpy())\n",
    "        if embeddings:\n",
    "            return np.mean(np.concatenate(embeddings), axis=0)\n",
    "        else:\n",
    "            return np.zeros((768,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data directory\n",
      "Found 1 PKL files\n",
      "Using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fader/Envs/se/lib64/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Processing Data and creating Cache...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87890eda85b8421780456aa632e32841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748bffc60cba45b1bc1590f3dcb62fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009347495aa94543a9525de43b7d4c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max roll up Rows: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144133/45417855.py:274: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  self.contData = torch.tensor(self.contData)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Cache File 1\n",
      "Created Cache\n",
      "Loading Cache File 1\n",
      "Done initializing Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144133/45417855.py:329: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.cacheDir / f\"dataCache{fileIDX}.pkl\")\n"
     ]
    }
   ],
   "source": [
    "data = HIEDATA2(\"./data\", debug=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pklData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# categCols = [            \"PatientAdministrationGenderCode\",\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#             \"SNOMED Codes 0\",\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#             \"SNOMED Codes 1\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     print(pklData.loc[pklData[\"Patient IDX\"] == 1][categCols])\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     print(pklData.loc[pklData[\"Patient IDX\"] == 1][categCols][\"Smoking Status\"].astype(\"string\").fillna(\"asd\"))\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mstack(\u001b[43mpklData\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProjected_Med_Embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# for col in pklData:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     print(col)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pklData' is not defined"
     ]
    }
   ],
   "source": [
    "# categCols = [            \"PatientAdministrationGenderCode\",\n",
    "#             \"SNOMED Codes 0\",\n",
    "#             \"SNOMED Codes 1\",\n",
    "#             \"SNOMED Codes 2\",\n",
    "#             \"SNOMED Codes 3\",\n",
    "#             \"SNOMED Codes Other\",\n",
    "#             \"Smoking Status\",\n",
    "#             \"Procedure Codes 0\",\n",
    "#             \"Procedure Codes 1\",\n",
    "#             \"Procedure Codes 2\",\n",
    "#             \"Procedure Codes 3\",\n",
    "#             \"Procedure Codes Other\",\n",
    "#             \"Urine Routine\",]\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     print(pklData.loc[pklData[\"Patient IDX\"] == 1][categCols].dtypes)\n",
    "#     print(pklData.loc[pklData[\"Patient IDX\"] == 1][categCols])\n",
    "#     print(pklData.loc[pklData[\"Patient IDX\"] == 1][categCols][\"Smoking Status\"].astype(\"string\").fillna(\"asd\"))\n",
    "\n",
    "print(np.stack(pklData[\"Projected_Med_Embeddings\"]).shape)\n",
    "# for col in pklData:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block to print data shapes and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 torch.Size([1656]) torch.Size([92]) torch.Size([141312]) torch.Size([5])\n",
      "\n",
      "continuous data breakdown:\n",
      "torch.Size([1656]) <class 'torch.Tensor'>\n",
      "\n",
      "categorical data breakdown:\n",
      "torch.Size([92]) <class 'torch.Tensor'>\n",
      "\n",
      "clinical data breakdown:\n",
      "torch.Size([141312]) <class 'torch.Tensor'>\n",
      "labels breakdown:\n",
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(data), 200):\n",
    "    print(f\"index: {i}\", data[i][0].shape, data[i][1].shape, data[i][2].shape, data[i][3].shape)\n",
    "i=60\n",
    "print()\n",
    "print(\"continuous data breakdown:\")\n",
    "print(data[i][0].shape, type(data[i][0]) )\n",
    "print()\n",
    "print(\"categorical data breakdown:\")\n",
    "print(data[i][1].shape, type(data[i][1]) )\n",
    "print()\n",
    "print(\"clinical data breakdown:\")\n",
    "print(data[i][2].shape, type(data[i][2]))\n",
    "print(\"labels breakdown:\")\n",
    "print(data[i][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1656, 92, 141312, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.getShapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422650009 314529007 423315002 73595000 40055000  160903007  36971009  59621000  5251000175109  162864005  160904001  73438004  741062008  444814009\n"
     ]
    }
   ],
   "source": [
    "categoricalColumns = [\n",
    "            \"PatientAdministrationGenderCode\",\n",
    "            \"Smoking Status\",\n",
    "            \"Urine Routine\",\n",
    "        ]\n",
    "categEmbedColumns = {\n",
    "            \"SnomedEmbed\": [\n",
    "                \"SNOMED Codes 0\",\n",
    "                \"SNOMED Codes 1\",\n",
    "                \"SNOMED Codes 2\",\n",
    "                \"SNOMED Codes 3\",\n",
    "                \"SNOMED Codes Other\",\n",
    "            ],\n",
    "            \"ProcedureEmbed\": [\n",
    "                \"Procedure Codes 0\",\n",
    "                \"Procedure Codes 1\",\n",
    "                \"Procedure Codes 2\",\n",
    "                \"Procedure Codes 3\",\n",
    "                \"Procedure Codes Other\",\n",
    "            ],\n",
    "        }\n",
    "\n",
    "for i in categEmbedColumns:\n",
    "    tempData = pklData[categEmbedColumns[i]]\n",
    "    tempData = tempData.astype(\"string\")\n",
    "    break\n",
    "\n",
    "print(\"\".join(tempData.loc[100].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MUFASAFull(nn.Module):\n",
    "    def __init__(self, contFeatureLen, categLen, clinicNotesLen, outputLen):\n",
    "        super(MUFASAFull, self).__init__()\n",
    "        #! # layers for continuous features branch\n",
    "        self.contInput = nn.Linear(contFeatureLen, 128)\n",
    "        self.inputNorm = nn.LayerNorm(128)\n",
    "        self.attention = nn.MultiheadAttention(128, 4)\n",
    "        self.lRelu = nn.LeakyReLU()\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        # ? Addition Layer\n",
    "        self.nextLayerNorm = nn.LayerNorm(128)\n",
    "        self.conv1 = nn.Linear(128, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.next2LayerNorm = nn.LayerNorm(512)\n",
    "        self.conv2 = nn.Linear(512, 128)\n",
    "        # ? Addition Layer\n",
    "\n",
    "        #! # layers for categorical features branch\n",
    "        self.categInput = nn.Linear(categLen, 128)\n",
    "        self.cat_2_layerNorm = nn.LayerNorm(128)\n",
    "        self.cat_3_self_attention = nn.MultiheadAttention(128, 4)\n",
    "        self.cat_4_conv1 = nn.Linear(256, 256)\n",
    "        self.cat_5_relu = nn.ReLU()\n",
    "        self.cat_dropout = nn.Dropout(0.4)\n",
    "        # ? addition\n",
    "        self.cat_branch_layerNorm = nn.LayerNorm(256)\n",
    "        self.cat_branch_conv2 = nn.Linear(256, 384)\n",
    "        self.cat_branch_relu = nn.ReLU()\n",
    "        self.cat_branch_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        #! # layers for clinical features branch\n",
    "        self.cliInput = nn.Linear(clinicNotesLen, 128)\n",
    "        self.cli_2_layerNorm = nn.LayerNorm(128)\n",
    "        self.cli_3_selfAtt = nn.MultiheadAttention(128, 4)\n",
    "        # ? addition\n",
    "        self.cli_4_layerNorm = nn.LayerNorm(128)\n",
    "        self.cli_5_conv1 = nn.Linear(128, 512)\n",
    "        self.cli_6_relu = nn.ReLU()\n",
    "        self.cli_6_1_dropout = nn.Dropout(0.4)\n",
    "        self.cli_7_layerNorm = nn.LayerNorm(512)\n",
    "        self.cli_8_conv2 = nn.Linear(512, 128)\n",
    "        # ? addition\n",
    "        # ? Fuse concatenation between ret1 from categorical and current\n",
    "        self.cli_9_layerNorm = nn.LayerNorm(384)\n",
    "        self.cli_10_conv3l = nn.Linear(384, 1536)\n",
    "        self.cli_11_conv3r = nn.Linear(384, 384)\n",
    "        self.cli_12_relu = nn.ReLU()\n",
    "        self.cli_12_1_dropout = nn.Dropout(0.3)\n",
    "        self.cli_13_conv4 = nn.Linear(1536, 384)\n",
    "        # ? Fuse addition between concat output, current, right branch conv,\n",
    "        # ? continuous branch, ret2 from categorical branch\n",
    "\n",
    "        #! Final Output from addition\n",
    "        self.out = nn.Linear(384, outputLen)\n",
    "\n",
    "    def forward(self, sample):\n",
    "        contIn, cateIn, clinIn = sample\n",
    "        # print(contIn.shape, cateIn.shape, clinIn.shape)\n",
    "        contOutput = self.continuousFeaturesForward(contIn)\n",
    "        ret1, ret2 = self.categoricalFeaturesForward(cateIn)\n",
    "        res = self.clinicalFeaturesForward(clinIn, ret1, ret2, contOutput)\n",
    "        res = self.out(res)\n",
    "        return res\n",
    "\n",
    "    def categoricalFeaturesForward(self, inp):\n",
    "        xa = self.categInput(inp)\n",
    "        x = xa.clone()\n",
    "        x = self.cat_2_layerNorm(x)\n",
    "        x = self.cat_3_self_attention(x, x, x, need_weights=False)\n",
    "        xb = torch.concatenate([x[0], xa], dim=1)\n",
    "        x = self.cat_4_conv1(xb)\n",
    "        x = self.cat_dropout(self.cat_5_relu(x))\n",
    "\n",
    "        xBran = self.cat_branch_layerNorm(xb)\n",
    "        ret1 = torch.add(xBran, x)\n",
    "        xBran = self.cat_branch_conv2(xBran)\n",
    "        ret2 = self.cat_branch_dropout(self.cat_branch_relu(xBran))\n",
    "        return ret1, ret2\n",
    "\n",
    "    def clinicalFeaturesForward(self, inp, ret1, ret2, contFeat):\n",
    "        xa = self.cliInput(inp)\n",
    "        x = xa.clone()\n",
    "        x = self.cli_2_layerNorm(x)\n",
    "        x = self.cli_3_selfAtt(x, x, x, need_weights=False)\n",
    "        # raise NotImplementedError(\"Change the skip strategy\")\n",
    "        x = torch.add(x[0], xa)\n",
    "        xb = self.cli_4_layerNorm(x)\n",
    "        x = self.cli_5_conv1(xb)\n",
    "        x = self.cli_6_1_dropout(self.cli_6_relu(x))\n",
    "        x = self.cli_7_layerNorm(x)\n",
    "        x = self.cli_8_conv2(x)\n",
    "        x = torch.add(x, xb)\n",
    "        xc = torch.concatenate([x, ret1], dim=1)\n",
    "        x = self.cli_9_layerNorm(xc)\n",
    "        xdl = self.cli_10_conv3l(x)\n",
    "        xdr = self.cli_11_conv3r(x)\n",
    "        x = self.cli_12_1_dropout(self.cli_12_relu(xdl))\n",
    "        x = self.cli_13_conv4(x)\n",
    "        # print(x.shape, xc.shape, contFeat.shape, xdr.shape, ret2.shape)\n",
    "        x = x + xc + nn.functional.pad(contFeat, (0, 256), value=0) + xdr + ret2\n",
    "        return x\n",
    "\n",
    "    def continuousFeaturesForward(self, inp):\n",
    "        x = self.contInput(inp)\n",
    "        sav0 = x.clone()\n",
    "        x = self.inputNorm(x)\n",
    "        x = self.attention(x, x, x, need_weights=False)\n",
    "        x = self.dropout1(self.lRelu(x[0]))\n",
    "        addOutput = torch.add(x, sav0)\n",
    "        x = self.nextLayerNorm(addOutput)\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout2(self.relu(x))\n",
    "        x = self.next2LayerNorm(x)\n",
    "        x = self.conv2(x)\n",
    "        output = torch.add(x, addOutput)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MUFASAFull(*data.getShapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl=DataLoader(data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5]) tensor([[ 0.5068, -1.0627, -1.0535,  1.0040, -1.2035],\n",
      "        [ 0.6805, -0.9053, -1.2376,  0.9532, -1.1185],\n",
      "        [ 0.6199, -1.5490, -1.1506,  0.5832, -1.4645],\n",
      "        [ 0.2582, -1.1938, -0.8834,  1.0256, -1.6013]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for d4 in dl:\n",
    "    cont, cate, clin, lab = d4\n",
    "    a=model([cont.float(), cate.float(), clin.float()])\n",
    "    print(a.shape, a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel((nn.Sigmoid()(a)>0.5).int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0427, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ls=nn.BCEWithLogitsLoss()\n",
    "l=ls(a, lab.float())\n",
    "# print(torch.mean(l.flatten()))\n",
    "print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
